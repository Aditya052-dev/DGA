**DGA Domain Detection using LSTM**
This project implements a deep learning model using Long Short-Term Memory (LSTM) networks to detect and classify malicious domains generated by Domain Generation Algorithms (DGAs). DGAs are used by malware to create a large number of domain names for their command and control (C2) servers, making them difficult to block. This model learns the character patterns of domain names to distinguish between legitimate (benign) domains and DGA-generated (malicious) ones.

Features

> LSTM-Based Model: Utilizes a Recurrent Neural Network (RNN) architecture, specifically LSTMs, which are excellent for learning from sequential data like text.

> Data Preprocessing: Includes robust preprocessing steps such as tokenization and padding, with careful handling to prevent data leakage.

> Model Training & Evaluation: Trains the model on a labeled dataset and evaluates its performance using accuracy and loss metrics.

> Training Visualization: Plots the model's accuracy and loss over epochs to visualize the learning process.

> Real-Time Prediction: Provides an interactive command-line interface to classify new domains on the fly.

Technology Stack
‚Ä¢	Python 3

‚Ä¢	TensorFlow / Keras: For building and training the deep learning model.

‚Ä¢	Pandas: For data manipulation and loading the dataset.

‚Ä¢	Scikit-learn: For splitting the data into training and testing sets.

‚Ä¢	Matplotlib: For visualizing the training history.
üìÇ Project Structure
.
‚îú‚îÄ‚îÄ dga_detection_lstm.py   # Main Python script to train and run the model
‚îú‚îÄ‚îÄ aditya.csv              # Sample dataset containing labeled domains
‚îî‚îÄ‚îÄ README.md               # You are here!

‚öôÔ∏è Setup and Installation
1.	Clone the repository:
2.	git clone [https://github.com/your-username/dga-detection-lstm.git](https://github.com/your-username/dga-detection-lstm.git)
3.	cd dga-detection-lstm
4.	Create a virtual environment (recommended):
5.	python -m venv venv
6.	source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
7.	Install the required libraries:
8.	pip install tensorflow pandas scikit-learn matplotlib

‚ñ∂Ô∏è How to Run
Execute the main Python script from your terminal. The script will automatically load the data, build the model, train it, evaluate it, and then prompt you for domains to classify.

python dga_detection_lstm.py

The script will first train the model, which may take a few minutes depending on your hardware. After training is complete, you will see an interactive prompt:

Enter a domain to classify (or 'quit' to exit):

You can then type any domain name and press Enter to see the classification result.

üß† Model Architecture

The neural network is a Sequential model built with Keras, consisting of the following layers:
1.	Embedding Layer: Converts the integer-encoded characters into dense vectors of a fixed size.
2.	LSTM Layer (x2): Two layers of LSTMs to capture the sequential patterns in the domain names. A Dropout layer is included between them to prevent overfitting.
3.	Dense Layer: A single neuron output layer with a sigmoid activation function, which outputs a probability score between 0 (legitimate) and 1 (DGA).
üìä Results and Limitations
The model's performance is evaluated on a held-out test set. Key metrics are:

‚Ä¢	Test Accuracy: The percentage of domains correctly classified.

‚Ä¢	Test Loss: The value of the binary_crossentropy loss function on the test set.

Important Note: The provided aditya.csv dataset is a small sample with only 300 domains. While it's useful for demonstrating the code, a production-level model requires a much larger and more diverse dataset (tens of thousands of domains) to achieve high accuracy and generalize well to new, unseen DGAs.\

üí° Future Improvements

‚Ä¢	Expand the Dataset: Train the model on a larger, more comprehensive dataset like DGArchive or public OSINT feeds.

‚Ä¢	Feature Engineering: Combine the LSTM approach with feature-based methods (e.g., domain length, entropy, n-gram analysis) to potentially improve performance.

‚Ä¢	Try Other Architectures: Experiment with different models like GRUs (Gated Recurrent Units) or 1D Convolutional Neural Networks (CNNs).

‚Ä¢	Hyperparameter Tuning: Optimize model parameters like embedding size, LSTM units, and learning rate.

